{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fighting Fire With Data - Divine Saungweme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each year, thousands of fires blaze across the African continent. Some are natural occurrences, part of a ‘fire cycle’ that can actually benefit some dryland ecosystems. Many are started intentionally, used to clear land or to prepare fields for planting. And some are wildfires, which can rage over large areas and cause huge amounts of damage. Whatever the cause, fires pour vast amounts of CO2 into the atmosphere, along with smoke that degrades air quality for those living downwind.\n",
    "\n",
    "Figuring out the dynamics that influence where and when these fires occur can help us to better understand their effects. And predicting how these dynamics will play out in the future, under different climatic conditions, could prove extremely useful. For this project, the goal is to do exactly that. The datasets contain aggregated data on burned areas across Zimbabwe for each month since 2001. There will be the burn area data which goes up to the end of 2013, along with some additional information (such as rainfall, temperature, land cover etc) that extends into the test period. The project is centred around building a model capable of predicting the burned area in different locations based on only this information. This information provides vital keys which can determine our future and is still relevant even to this day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "jtplot.style(context='notebook', theme='monokai', grid='False')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-85c7e837c6e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "train_set, test_set = pd.read_csv('Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I need to drop attributes with a very low variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = train_set.nunique()[train_set.nunique()==1].index\n",
    "\n",
    "for dropper in train_set, test_set:\n",
    "    dropper.drop(drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how all these attributes relate to eachother using correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "sns.heatmap(train_set.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the other attributes relate with the 'burn_area' attribute (which is the target) through correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.corr()['burn_area'].sort_values().plot(kind='bar', figsize=(18, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'ID' attribute can be a useful key. It can provide us with month and year attributes. Let's see what I can salvage from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['date'] = pd.to_datetime(train_set['ID'].apply(lambda x: x.split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['month'] = train_set['date'].dt.month\n",
    "train_set['year'] = train_set['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, now we have much more useful attributes in hand, let's poke around with them for a little bit in Data Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.groupby('month').mean().reset_index().plot(x='month', y='burn_area', kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In relation to the seasonal conditions in my country, it makes super sense that the 'burn_area' starts to rise after the middle months. At this time of the year, in my country, the weather starts as windy during the 8th month. The 9th and 10th months are popularly known for their solar intensity and according to the Data Visualization, it can be concluded with evidence that indeed windy and sunny conditions are more favourable to forest fires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.groupby('year').mean().reset_index().plot(x='year', y='burn_area', ylim=(0, 0.03))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the 'burn_area' with 'precipitation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = train_set.groupby('date').mean().reset_index().plot(y='burn_area', x='date', figsize=(18, 5))\n",
    "train_set.groupby('date').mean().reset_index().plot(y='precipitation', x='date', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot is expressing the most obvious of expositions. When there is high precipitation is unlikely for Forest Fires to burn a large area and the plot is just clear showing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = train_set.groupby('date').mean().reset_index().plot(y='burn_area', x='date', figsize=(18, 5))\n",
    "train_set.groupby('date').mean().reset_index().plot(y='climate_vap', x='date', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_set.sample(500)['climate_pr'], train_set.sample(500)['burn_area'], alpha=0.3)\n",
    "plt.xlabel('Climate Precipitation')\n",
    "plt.ylabel('Burn Area')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we can deduce that fires occur when there is very little rain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the longitude and latitude points and see what we can come up with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.plot(x='lon', y='lat', kind='scatter', )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, what do you know? If it isn't the map of Zimbabwe itself. This clearly shows us that the data is collected from various parts of the country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data For Training\n",
    "\n",
    "We don't want to just split randomly - this would give us artificially high scores. Instead, let's use the last 3 years of the dataset for validation to more closely match the test configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = train_set.copy().dropna()\n",
    "train = train_all.loc[train_all.date < '2011-01-01']\n",
    "valid = train_all.loc[train_all.date > '2010-12-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take the columns (attributes) which are essential for our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_cols = ['climate_aet', 'climate_def',\n",
    "       'climate_pdsi', 'climate_pet', 'climate_pr', 'climate_ro',\n",
    "       'climate_soil', 'climate_srad', 'climate_tmmn',\n",
    "       'climate_tmmx', 'climate_vap', 'climate_vpd', 'climate_vs', 'elevation',\n",
    "       'landcover_0', 'landcover_1', 'landcover_2', 'landcover_3',\n",
    "       'landcover_4', 'landcover_5', 'landcover_6', 'landcover_7',\n",
    "       'landcover_8', 'precipitation']\n",
    "target_col = 'burn_area'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Get our X and y training and validation sets ready\n",
    "X_train, y_train = train[in_cols], train[target_col]\n",
    "X_valid, y_valid = valid[in_cols], valid[target_col]\n",
    "\n",
    "# Create and fit the model\n",
    "model = CatBoostRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = model.predict(X_valid)\n",
    "\n",
    "# Score\n",
    "mean_squared_error(y_valid, preds)**0.5 # RMSE - Lower is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the model performed well on the validation set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
